{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3 - DATA.ML.360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./a3_venv/lib/python3.9/site-packages (2.1.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./a3_venv/lib/python3.9/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./a3_venv/lib/python3.9/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./a3_venv/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in ./a3_venv/lib/python3.9/site-packages (from pandas) (1.26.2)\n",
      "Requirement already satisfied: six>=1.5 in ./a3_venv/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the '/Users/laurira/uni/recsys/assignment3/a3_venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: surprise in ./a3_venv/lib/python3.9/site-packages (0.1)\n",
      "Requirement already satisfied: scikit-surprise in ./a3_venv/lib/python3.9/site-packages (from surprise) (1.1.3)\n",
      "Requirement already satisfied: joblib>=1.0.0 in ./a3_venv/lib/python3.9/site-packages (from scikit-surprise->surprise) (1.3.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in ./a3_venv/lib/python3.9/site-packages (from scikit-surprise->surprise) (1.26.2)\n",
      "Requirement already satisfied: scipy>=1.3.2 in ./a3_venv/lib/python3.9/site-packages (from scikit-surprise->surprise) (1.11.4)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the '/Users/laurira/uni/recsys/assignment3/a3_venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas\n",
    "%pip install surprise\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating\n",
       "0      196       242       3\n",
       "1      186       302       3\n",
       "2       22       377       1\n",
       "3      244        51       2\n",
       "4      166       346       1"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data file and see how it looks like\n",
    "df = pd.read_csv('u.data', sep='\\t', header=None)\n",
    "\n",
    "# Add column names and check few rows of the dataset\n",
    "df.columns = [\"user_id\", \"movie_id\", \"rating\", \"timestamp\"]\n",
    "df = df.drop(\"timestamp\", axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Weighted ratings\n",
    "\n",
    "**Modified method for sequential recommendations**\n",
    "\n",
    "I chose to calculate the average weighted ratings to improve the basic group recommendations. This method works by adjusting the predicted ratings for each movie with individual users average rating scores. This way each users preferences with the suggested movies are taken better into account, leading to better personalized recommendations for the group.This weighted approach to recommendations also improves the collaboration since all users preferences are taken into account.\n",
    "\n",
    "The differences in recommendations are not very significant with small group sizes. However, when increasing the size to > 10 the recommendations start to differ more.\n",
    "\n",
    "**These are the key steps in the method:**\n",
    "- Calculate weights for each user by calculating the average from users predicted ratings.\n",
    "- Adjust the original prediction with the weight.\n",
    "- Normalize each movie prediciton by dividing the weighted ratings with total weights.\n",
    "- Get the top 10 best scoring movies\n",
    "\n",
    "The practical implementation below has more specific details on what is done in each step of the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This helper function gets the sequence recommendations for the group as a parameter.\n",
    "# Then those ratings are adjusted with the weighted averages, \n",
    "# and the top recommendations are returned.\n",
    "def adjust_ratings(result):\n",
    "    # Create a dataframe from the sequence results\n",
    "    group_df = pd.DataFrame(result, columns=[\"user_id\", \"movie_id\", \"predicted_rating\"])\n",
    "\n",
    "    # Create a dataframe for user weights &\n",
    "    # calculate the weight for each user from their average predicted rating\n",
    "    user_weights = group_df.groupby('user_id')['predicted_rating'].mean().reset_index()\n",
    "    user_weights.columns = ['user_id', 'weight']\n",
    "\n",
    "    # Merge weights with the original group recommendations\n",
    "    group_df = pd.merge(group_df, user_weights, on='user_id', how='left')\n",
    "\n",
    "    # Multioply the original prediction with the user weight -> weighted rating for each item\n",
    "    group_df['weighted_rating'] = group_df['predicted_rating'] * group_df['weight']\n",
    "\n",
    "    # Divide total weighted ratings by total weights -> average rating for each tiem\n",
    "    weighted_ratings = group_df.groupby('movie_id')['weighted_rating'].sum() / group_df.groupby('movie_id')['weight'].sum()\n",
    "\n",
    "    # Get top 10 recommendations based on the weighted average ratings\n",
    "    top_recommendations = weighted_ratings.sort_values(ascending=False)[:10]\n",
    "    return top_recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating sequential group recommendations\n",
    "\n",
    "I chose to change the basic recommendation method from Assignment 2 to Singular Value Decomposition. This is because I wanted something more accurate and faster than the previous implementation I had. SVD is used to create the predicitons. Otherwise the group recommendations are created the same way, with the change of creating them in sequences.\n",
    "\n",
    "**Key steps:**\n",
    "- Train the model sequentially\n",
    "- Create group recommendations for that sequence\n",
    "- Combine the sequences recommendations together\n",
    "\n",
    "#### Singular Value Decomposition (SVD)\n",
    "\n",
    "The initial group recommendations are created with the SVD algorithm. With this algorithm, we split the user-item-rating matrix into three matrices: a user matrix, a diagonal matrix of singular values, and an item matrix After that the recommendations for unrated movies are done by multiplying the matrices.\n",
    "\n",
    "This article goes more in depth and helped me understand the general priciples on how SVD works:\n",
    "https://gregorygundersen.com/blog/2018/12/10/svd/\n",
    "\n",
    "Other sources used:\n",
    "\n",
    "https://towardsdatascience.com/how-to-build-a-movie-recommendation-system-67e321339109\n",
    "\n",
    "https://www.math3ma.com/blog/understanding-entanglement-with-svd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise import SVD\n",
    "\n",
    "def create_group_recommendations(users, sequences):\n",
    "    # Create a dataset\n",
    "    reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "    # Save recommendations from each sequence here\n",
    "    group_recommendations = []\n",
    "\n",
    "    # Loop through sequences\n",
    "    for sequence in range(sequences):\n",
    "        # Train the dataset for each round\n",
    "        data = Dataset.load_from_df(df[['user_id', 'movie_id', 'rating']], reader)\n",
    "        trainset = data.build_full_trainset()\n",
    "\n",
    "        # Intialize the svd algorithm and train the dataset\n",
    "        svd = SVD()\n",
    "        svd.fit(trainset)\n",
    "\n",
    "        # Go thorugh each user and create predictions.\n",
    "        for user_id in users:\n",
    "            # Get movies that user hasnt rated yet\n",
    "            user_ratings = df[df['user_id'] == user_id]\n",
    "            user_unrated_movies = df[~df['movie_id'].isin(user_ratings['movie_id'])]['movie_id'].unique()\n",
    "\n",
    "            user_recommendations = []\n",
    "\n",
    "            # Loop through the unrated movies\n",
    "            for movie_id in user_unrated_movies:\n",
    "                # Create a predicted score for the movie\n",
    "                prediction = svd.predict(user_id, movie_id)\n",
    "                # Add it to the recommendations\n",
    "                user_recommendations.append((user_id, movie_id, prediction.est))\n",
    "\n",
    "            # Retrun the top 10 best rated predictions\n",
    "            user_recommendations = sorted(user_recommendations, key=lambda x: x[2], reverse=True)\n",
    "            group_recommendations.extend(user_recommendations)\n",
    "\n",
    "        # Adjust the sequence recommendations with the weighted averages\n",
    "        sequence_recommendations = adjust_ratings(group_recommendations)\n",
    "\n",
    "        # Show the current sequence recommendations to the user\n",
    "        print(\"Recomenndations for sequence: \" + str(sequence + 1))\n",
    "        display(sequence_recommendations)\n",
    "\n",
    "    return print(\"Recommendations generated succesfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the implementation\n",
    "\n",
    "Next we check how the modified recommendation method performs by creating top 10 recommendations for 3 users in 3 sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recomenndations for sequence: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "movie_id\n",
       "357    4.560872\n",
       "474    4.273590\n",
       "408    4.267714\n",
       "318    4.214869\n",
       "483    4.205073\n",
       "484    4.190147\n",
       "498    4.103931\n",
       "603    4.100568\n",
       "647    4.097499\n",
       "430    4.091515\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recomenndations for sequence: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "movie_id\n",
       "357    4.366959\n",
       "408    4.338959\n",
       "483    4.285636\n",
       "169    4.160245\n",
       "318    4.142754\n",
       "285    4.134694\n",
       "498    4.131158\n",
       "474    4.129076\n",
       "484    4.114929\n",
       "513    4.082609\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recomenndations for sequence: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "movie_id\n",
       "357    4.352143\n",
       "408    4.302191\n",
       "483    4.264115\n",
       "474    4.154972\n",
       "169    4.132826\n",
       "484    4.106291\n",
       "513    4.095060\n",
       "511    4.094546\n",
       "302    4.091496\n",
       "285    4.084510\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations generated succesfully\n"
     ]
    }
   ],
   "source": [
    "user_list = [1, 5, 20]\n",
    "sequences = 3\n",
    "create_group_recommendations(user_list, 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
